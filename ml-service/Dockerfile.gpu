# GPU-enabled ML Service Dockerfile - Multi-stage build
# Stage 1: Builder - Install dependencies
FROM nvidia/cuda:11.8-runtime-ubuntu22.04 AS builder

# Set environment variables
ENV PYTHONDONTWRITEBYTECODE=1 \
    PYTHONUNBUFFERED=1 \
    PIP_NO_CACHE_DIR=1 \
    PIP_DISABLE_PIP_VERSION_CHECK=1

WORKDIR /app

# Install Python and pip
RUN apt-get update && apt-get install -y --no-install-recommends \
    python3 \
    python3-pip \
    python3-venv \
    python3-dev \
    && rm -rf /var/lib/apt/lists/* \
    && ln -s /usr/bin/python3 /usr/bin/python

# Copy requirements first for better caching
COPY requirements.txt .

# Create virtual environment and install dependencies
RUN python -m venv /opt/venv
ENV PATH="/opt/venv/bin:$PATH"

# Install base Python dependencies
RUN pip install --no-cache-dir flask==3.0.0 flask-cors==4.0.0 \
    transformers==4.36.0 gunicorn==21.2.0 python-dotenv==1.0.0 \
    pytest==7.4.3 hypothesis==6.92.0

# Install PyTorch with CUDA support
RUN pip install --no-cache-dir torch --index-url https://download.pytorch.org/whl/cu118

# Stage 2: Production - Runtime image
FROM nvidia/cuda:11.8-runtime-ubuntu22.04 AS production

# Set environment variables
ENV PYTHONDONTWRITEBYTECODE=1 \
    PYTHONUNBUFFERED=1 \
    CUDA_VISIBLE_DEVICES=0 \
    USE_GPU=true \
    PATH="/opt/venv/bin:$PATH"

WORKDIR /app

# Install Python runtime and curl for health checks
RUN apt-get update && apt-get install -y --no-install-recommends \
    python3 \
    curl \
    && rm -rf /var/lib/apt/lists/* \
    && ln -s /usr/bin/python3 /usr/bin/python

# Create non-root user for security
RUN groupadd -r mlservice && useradd -r -g mlservice mlservice

# Copy virtual environment from builder
COPY --from=builder /opt/venv /opt/venv

# Copy application code
COPY app/ ./app/

# Set ownership to non-root user
RUN chown -R mlservice:mlservice /app

# Switch to non-root user
USER mlservice

# Expose port
EXPOSE 5000

# Health check
HEALTHCHECK --interval=30s --timeout=10s --start-period=30s --retries=3 \
    CMD curl -f http://localhost:5000/health || exit 1

# Start with gunicorn for production (2 workers for GPU to avoid memory issues)
CMD ["gunicorn", "--bind", "0.0.0.0:5000", "--workers", "2", "--timeout", "120", "app.main:app"]
